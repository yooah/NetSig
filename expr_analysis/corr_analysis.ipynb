{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Find modules based on correlation between expression and signatures\n",
    "\n",
    "1) select genes with significant correlations\n",
    "1-1) all significant genes\n",
    "1-2) subset of genes (DNA metabolic etc)\n",
    "2) cluster genes\n",
    "input: (output files from comp_corr_sigma.ipynb)\n",
    "corr_count_file \"results/corr_expr_sigma_count.tsv\"\n",
    "pv_count_file \"results/corr_pv_expr_sigma_count.tsv\"\n",
    "\n",
    "output: \n",
    "cluste id file \"results/all_cluster_id.tsv\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import scipy \n",
    "import scipy.stats as ss\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "import sklearn.cluster as cluster\n",
    "from sklearn import metrics\n",
    "import statsmodels.stats.multitest as ssm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input files\n",
    "corr_count_file = \"results/corr_expr_sigma_count.tsv\"\n",
    "pv_count_file = \"results/corr_pv_expr_sigma_count.tsv\"\n",
    "go_file = \"data/c5.bp.v6.1.symbols.gmt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read correlation file\n",
    "pv_count = pd.read_csv(pv_count_file, sep=\"\\t\", index_col=0)\n",
    "corr_count = pd.read_csv(corr_count_file, sep=\"\\t\", index_col=0)\n",
    "\n",
    "# take care of duplicates\n",
    "def rename_dp(df):\n",
    "    df.index = df.index + df.groupby(level=0).cumcount().astype(str).replace('1', '_1').replace('2', '_2').replace('0','')\n",
    "\n",
    "rename_dp(corr_count)\n",
    "rename_dp(pv_count)\n",
    "\n",
    "sigs = [\"1D\", \"2C\", \"2D\", \"3C\", \"3D\", \"5D\", \"8C\", \"8D\", \"13C\", \"13D\"]\n",
    "\n",
    "corr_count = corr_count[sigs]\n",
    "pv_count = pv_count[sigs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D\n",
      "6\n",
      "2C\n",
      "157\n",
      "2D\n",
      "7\n",
      "3C\n",
      "2311\n",
      "3D\n",
      "3259\n",
      "5D\n",
      "93\n",
      "8C\n",
      "1343\n",
      "8D\n",
      "14\n",
      "13C\n",
      "760\n",
      "13D\n",
      "838\n"
     ]
    }
   ],
   "source": [
    "# select genes based on pvalues and correlation\n",
    "# threshold for correlation coefs and p-values\n",
    "corr_th = 0.3\n",
    "fdr_th = 0.005\n",
    "\n",
    "sig_corr_dic = {}\n",
    "sig_corr_genes = set([])\n",
    "\n",
    "for sig in sigs:\n",
    "    print(sig)\n",
    "    rej, pvc, a, b = ssm.multipletests(pv_count[sig], fdr_th, method=\"fdr_bh\")\n",
    "    sig_corr = pv_count.index[rej & ((corr_count[sig] >= corr_th)|(corr_count[sig] <= -corr_th))]\n",
    "    print(len(sig_corr))\n",
    "    if len(sig_corr) == 0:\n",
    "        continue\n",
    "    sig_corr_dic[sig] = sig_corr\n",
    "    sig_corr_genes = sig_corr_genes.union(sig_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GO genes\n",
    "lines = [l.split() for l in open(go_file).readlines()]\n",
    "go_dic = {}\n",
    "for l in lines:\n",
    "    go_dic[l[0]] = l[2:]\n",
    "    \n",
    "# GO_meta_genes\n",
    "dna_meta_genes = list(filter(lambda l: l[0] == \"GO_DNA_METABOLIC_PROCESS\", lines))[0][2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find correlation table only for genes of interst\n",
    "genes_of_interest = sig_corr_genes\n",
    "def create_corr_dic(corr_df, genes_of_interest):\n",
    "    corr_subset = corr_df[corr_df.index.isin(genes_of_interest)]\n",
    "    return corr_subset\n",
    "\n",
    "corr_count_selected = create_corr_dic(corr_count, genes_of_interest)\n",
    "corr_count_meta = create_corr_dic(corr_count_selected, dna_meta_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options for clustering\n",
    "GO=\"all\"\n",
    "if GO == \"META\":\n",
    "    matrix_to_cluster = corr_count_meta\n",
    "    prefix = \"meta_\" \n",
    "    # sig_go_dic = sig_meta_go_dic\n",
    "    subset_genes = dna_meta_genes \n",
    "    denom=10\n",
    "    step=2\n",
    "elif GO == \"all\":\n",
    "    matrix_to_cluster = corr_count_selected\n",
    "    prefix = \"all_\" \n",
    "    # sig_go_dic = go_dic\n",
    "    subset_genes =  list(corr_count.index)\n",
    "    denom=10\n",
    "    step=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "# Clustering genes:\n",
    "# Step 1: k-means clustering\n",
    "labels_all = []\n",
    "for ri in range(100):\n",
    "    if ri%10 == 0:\n",
    "        print(ri)\n",
    "    clusterer_ri = MiniBatchKMeans(n_clusters=(int(ri/denom)+1)*step, random_state=ri)\n",
    "    labels = clusterer_ri.fit_predict(matrix_to_cluster)\n",
    "    labels_all.append(labels)\n",
    "\n",
    "labels_df = pd.DataFrame(labels_all, columns=matrix_to_cluster.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "# Step 2: find consensus score for each \n",
    "def count_consensus(df, label):\n",
    "    return (df == label).astype(int).sum(1)\n",
    "\n",
    "consensus_df = pd.DataFrame()\n",
    "labels_T = labels_df.T\n",
    "for i in range(labels_df.shape[1]):\n",
    "    if (i%1000==0): # print progress\n",
    "        print(i)\n",
    "    consensus_df[i] = count_consensus(labels_T, labels_T.iloc[i,:])\n",
    "\n",
    "corr_consensus_summary_file = \"../results/\"+prefix+\"corr_consensus.tsv\"\n",
    "consensus_df.columns=consensus_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: hierarchical clustering\n",
    "consensus_mat = consensus_df.as_matrix()\n",
    "link_matrix = sch.linkage(consensus_mat, method=\"complete\", metric=\"cosine\") \n",
    "cluster_id_df = pd.DataFrame(index=matrix_to_cluster.index)\n",
    "nrange = range(7, 8)\n",
    "for n_clusters in nrange:\n",
    "    print(n_clusters)\n",
    "    th = [x[2] for x in link_matrix][-n_clusters]\n",
    "    labels = sch.fcluster(link_matrix, th, criterion='distance')\n",
    "    cluster_id_df[\"k=\"+str(n_clusters)] = labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the results\n",
    "cluster_id_df.to_csv(\"../results/\"+prefix+\"cluster_id.tsv\", sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
